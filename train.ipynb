{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5e158c-31ce-4884-8801-6329860a7770",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    EnsureChannelFirst,\n",
    "    ScaleIntensity,\n",
    "    Resized,\n",
    "    RandFlip,\n",
    "    RandRotate90,\n",
    "    RandZoom,\n",
    "    RandGaussianNoise,\n",
    "    ToTensor,\n",
    ")\n",
    "from monai.data import Dataset, DataLoader, CacheDataset\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.inferers import sliding_window_inference\n",
    "from torch.optim import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import glob\n",
    "from utils.CIS_UNet import CIS_UNet\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab8fa78-db73-42ba-88be-fe6a32837f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mha_files = sorted(glob.glob(\"data/masks/*.mha\"))  \n",
    "image_files = sorted(glob.glob(\"data/images/*.png\"))  \n",
    "data_dicts = [{\"mha\": mha, \"image\": img} for mha, img in zip(mha_files, image_files)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca8b839-9d64-4dc4-96e1-eefb511c7ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files, val_files = train_test_split(data_dicts, test_size=0.2, random_state=42)\n",
    "\n",
    "train_transforms = Compose([\n",
    "    LoadImage(keys=[\"mha\", \"image\"]),\n",
    "    EnsureChannelFirst(keys=[\"mha\", \"image\"]),\n",
    "    ScaleIntensity(keys=[\"mha\"]),\n",
    "    Resized(keys=[\"image\"], spatial_size=(256, 256)),\n",
    "    RandFlip(keys=[\"mha\", \"image\"], prob=0.5, spatial_axis=0),\n",
    "    RandRotate90(keys=[\"mha\", \"image\"], prob=0.5),\n",
    "    RandZoom(keys=[\"mha\", \"image\"], prob=0.2, min_zoom=0.9, max_zoom=1.1),\n",
    "    RandGaussianNoise(keys=[\"mha\"], prob=0.1),\n",
    "])\n",
    "\n",
    "val_transforms = Compose([\n",
    "    LoadImage(keys=[\"mha\", \"image\"]),\n",
    "    EnsureChannelFirst(keys=[\"mha\", \"image\"]),\n",
    "    ScaleIntensity(keys=[\"mha\"]),\n",
    "    Resized(keys=[\"image\"], spatial_size=(256, 256)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279f1473-64b1-4b81-b6ed-d721d384e32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CacheDataset(data=train_files, transform=train_transforms, cache_rate=0.8)\n",
    "val_dataset = CacheDataset(data=val_files, transform=val_transforms, cache_rate=0.8)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f7226c-c542-4288-a164-3566fa9a14e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CIS_UNet(spatial_dims=3, \n",
    "                 in_channels=1, \n",
    "                 num_classes=24, \n",
    "                 encoder_channels=[64, 64, 128, 256],\n",
    "                 feature_size=48).to(device)\n",
    "\n",
    "loss_function = DiceCELoss(include_background=True, to_onehot_y=True, softmax=True)\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b095868d-f6e9-4908-b1c1-d19bc4e4319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 50\n",
    "val_interval = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a48845-f523-4fc6-b99d-dfd8019ae305",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(max_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{max_epochs}\")\n",
    "    \n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch_data in train_loader:\n",
    "        mha_batch = batch_data[\"mha\"].to(device)\n",
    "        image_batch = batch_data[\"image\"].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(mha_batch)\n",
    "        loss = loss_function(outputs, image_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    print(f\"Average Training Loss: {epoch_loss / len(train_loader):.4f}\")\n",
    "    \n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        dice_scores = []\n",
    "        with torch.no_grad():\n",
    "            for val_data in val_loader:\n",
    "                mha_batch = val_data[\"mha\"].to(device)\n",
    "                image_batch = val_data[\"image\"].to(device)\n",
    "                outputs = sliding_window_inference(mha_batch, (128, 128, 128), 4, model)\n",
    "                dice_scores.append(dice_metric(outputs, image_batch).item())\n",
    "        print(f\"Validation Dice Score: {sum(dice_scores) / len(dice_scores):.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(), \"cis_unet.pth\")\n",
    "print(\"Training Complete. Model saved as cis_unet.pth.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
