{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316a8228-47bf-4442-9b0b-51d5c1130ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "from torch.utils.data import DataLoader\n",
    "from monai.data import CacheDataset\n",
    "from monai.inferers import sliding_window_inference\n",
    "import SimpleITK as sitk\n",
    "import seg_metrics.seg_metrics as sg\n",
    "from sklearn.model_selection import KFold\n",
    "from utils.dataset_processor import DatasetProcessor, image_and_masks_paths\n",
    "from utils.CIS_UNet import CIS_UNet\n",
    "from utils.save_volumes import save_volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f62e48-426b-48c7-bdf3-ba2f5f6b1470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an argument parser to handle command-line arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--data_dir\", type=str, required=True, help=\"Path to the root directory of the dataset\")\n",
    "parser.add_argument(\"--saved_model_dir\", type=str, required=True, help=\"Path to the root directory where the best model is saved\")\n",
    "parser.add_argument(\"--results_dir\", type=str, required=True, help=\"Path where the results will be stored!\")\n",
    "parser.add_argument(\"--num_classes\", type=int, default=24, help=\"Number of classes for segmentation\")\n",
    "parser.add_argument(\"--patch_size\", type=int, default=128, help=\"Size of patches for training\")\n",
    "parser.add_argument(\"--spatial_dims\", type=int, default=3, help=\"For 3D data it is 3 for 2D data it is 2\")\n",
    "parser.add_argument(\"--feature_size\", type=int, default=48, help=\"Initial Filters for SegResNet Model\")\n",
    "parser.add_argument(\"--num_samples\", type=int, default=4, help=\"Number of Samples per batch\")\n",
    "parser.add_argument(\"--num_folds\", type=int, default=4, help=\"K for K-fold Cross-Validation\")\n",
    "parser.add_argument(\"--in_channels\", type=int, default=1, help=\"Number of input channels\")\n",
    "parser.add_argument(\"--encoder_channels\", nargs=\"+\", type=int, default=[64, 64, 128, 256], help=\"Number of encoder channels\")\n",
    "parser.add_argument(\"--norm_name\", type=str, default='instance', help=\"Type of normalization\")\n",
    "\n",
    "args = parser.parse_args()  # Parse command-line arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae66f5b8-b580-480d-bb8a-68611caaebdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*\"*100)\n",
    "print(args)\n",
    "print(\"*\"*100)\n",
    "skf = KFold(n_splits=args.num_folds, shuffle=True, random_state=92)\n",
    "files = image_and_masks_paths(args.data_dir)\n",
    "processor = DatasetProcessor(args.data_dir)\n",
    "for fold, (train_indices, val_indices) in enumerate(skf.split(files)):\n",
    "    print(f\"Processing Fold {fold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4bf9c7-1a17-4f6f-b9c2-b73771651d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_files = [files[i] for i in val_indices]        \n",
    "val_images = [item['image'].split('/')[-1].split('.')[0] for item in val_files]\n",
    "print(f\"Validation Images Names: {', '.join(val_images)}\")\n",
    "val_transforms = processor.get_val_transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb7106b-81d5-4df9-b87e-3b0e2328dc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CIS_UNet(spatial_dims=args.spatial_dims, \n",
    "                 in_channels=args.in_channels, \n",
    "                 num_classes=args.num_classes, \n",
    "                 encoder_channels=args.encoder_channels,\n",
    "                 feature_size=args.feature_size)\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Model is defined with total paramters: {num_params}\\n\")\n",
    "print(f\"Model is loading to the appropriate device...\\n\")        \n",
    "if torch.cuda.device_count() > 1:\n",
    "    print('There are more than 1 GPUs... Hurray... Parallel Processing\\n')\n",
    "    model = torch.nn.DataParallel(model)  # Wrap the model for multi-GPU training\n",
    "elif torch.cuda.device_count() == 1:\n",
    "    print('There is only 1 GPU... Loading model onto it\\n')\n",
    "else:\n",
    "    print(\"No GPU Detected!!!\\n\")\n",
    "            \n",
    "model = model.to(device)\n",
    "print(\"Model loaded to the appropriate device...\\n\")\n",
    "        \n",
    "print(f\"Loading the Weights of the Trained Model for Fold {fold}...\\n\")\n",
    "model_path = os.path.join(args.saved_model_dir,\"Fold\" + str(fold) + \"_\" + \"best_metric_model.pth\")\n",
    "print(f\"Loading Model: {model_path}\\n\")\n",
    "state_dict = torch.load(model_path)\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    new_state_dict[k[7:] if k.startswith('module.') else k] = v\n",
    "model.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960c03d7-dc80-48ca-8c53-d8c02a0e2d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cpus = torch.get_num_threads()\n",
    "val_ds = CacheDataset(data=val_files, transform=val_transforms, cache_num=len(val_files), cache_rate=1.0, num_workers=0)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=0, pin_memory=True)\n",
    "print(\"Dataset is loaded and prepared for validation...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da869f8f-b99b-4529-be87-4fb888e40466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the results directory for the current fold\n",
    "result_dir = os.path.join(args.results_dir, f'Fold{fold}')\n",
    "os.makedirs(result_dir,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95628196-7751-4e08-8848-c4fbb7db3b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "individual_dices = {}\n",
    "individual_surface_scores = {}\n",
    "mean_dice_coeff = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9928b4ee-ca2a-4068-b511-d343222097d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable gradient computation\n",
    "with torch.no_grad():\n",
    "    for i, batch1 in enumerate(val_loader):\n",
    "        test_inputs, test_labels = batch1[\"image\"].to(device), batch1[\"label\"].to(device)\n",
    "        test_outputs = sliding_window_inference(test_inputs, \n",
    "                                                (args.patch_size, args.patch_size, args.patch_size), \n",
    "                                                args.num_samples, model)\n",
    "\n",
    "        file_path = val_ds[i]['image_meta_dict']['filename_or_obj']\n",
    "        vol_name = os.path.basename(file_path).split('.')[0]\n",
    "        print(f'Processing Volume: {vol_name}')\n",
    "                \n",
    "        # Save the volumes\n",
    "        save_volumes(\n",
    "            test_img=test_inputs,\n",
    "            test_label=test_labels,\n",
    "            test_outputs=test_outputs,\n",
    "            vol_name=vol_name,\n",
    "            results_dir=result_dir\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cadd23a-0a0f-42fb-adaa-dd69f1547921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics for each fold\n",
    "gdth_fpaths = sorted(glob.glob(os.path.join(result_dir, '*original.nii.gz')))\n",
    "pred_fpaths = sorted(glob.glob(os.path.join(result_dir, '*predicted.nii.gz')))\n",
    "labels_fpaths = [{\"gdth_fpath\": gdth_label, \"pred_fpath\": pred_label} for gdth_label, pred_label in zip(gdth_fpaths, pred_fpaths)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909a303e-ef1e-4669-8849-926a7bc5f1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_results = {}\n",
    "msd_results = {}\n",
    "labels = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
    "segment_names = {\n",
    "    0: \"Aorta\", 1: \"Left Subclavian Artery\", 2: \"Celiac Artery\",\n",
    "    3: \"SMA\", 4: \"Left Renal Artery\", 5: \"Right Renal Artery\",\n",
    "    6: \"Left Common Iliac Artery\", 7: \"Right Common Iliac Artery\",\n",
    "    8: \"Innominate Artery\", 9: \"Left Common Carotid\", 10: \"Right External Iliac Artery\",\n",
    "    11: \"Right Internal Iliac Artery\", 12: \"Left External Iliac Artery\",\n",
    "    13: \"Left Internal Iliac Artery\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2011669b-2629-40a4-9de8-f73c3c7a19cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics for each volume\n",
    "for label_fp in labels_fpaths:\n",
    "    gdth_fpath = label_fp['gdth_fpath']\n",
    "    pred_fpath = label_fp['pred_fpath']\n",
    "    vol_name = os.path.basename(gdth_fpath).split(\"_\")[0]\n",
    "\n",
    "    # Read images and convert them to numpy arrays\n",
    "    gdth_img = sitk.ReadImage(gdth_fpath)\n",
    "    gdth_np = sitk.GetArrayFromImage(gdth_img)\n",
    "    pred_img = sitk.ReadImage(pred_fpath)\n",
    "    pred_np = sitk.GetArrayFromImage(pred_img)\n",
    "    spacing = np.array(list(reversed(pred_img.GetSpacing())))\n",
    "\n",
    "    print(f\"Processing {vol_name} for metrics computation ...\")\n",
    "\n",
    "    # Calculate metrics\n",
    "    metrics = sg.write_metrics(\n",
    "        labels=labels,\n",
    "        gdth_img=gdth_np,\n",
    "        pred_img=pred_np,\n",
    "        csv_file=None,\n",
    "        spacing=spacing,\n",
    "        metrics=['msd', 'dice']\n",
    "    )\n",
    "\n",
    "    dice_results[vol_name] = metrics[0]['dice']\n",
    "    msd_results[vol_name] = metrics[0]['msd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff6ded6-3b36-4acc-8053-f546e4d8079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the metrics to CSV files\n",
    "df_msd = pd.DataFrame(msd_results).T\n",
    "df_msd[\"Labels' Avg\"] = df_msd.mean(axis=1)\n",
    "df_msd.loc['Volume Avg'] = df_msd.mean(axis=0)\n",
    "df_msd = df_msd.rename(index=segment_names)\n",
    "df_msd.index.names = ['Segments']\n",
    "df_msd.to_csv(os.path.join(result_dir, \"test_msd.csv\"))\n",
    "\n",
    "df_dice = pd.DataFrame(dice_results).T\n",
    "df_dice[\"Labels' Avg\"] = df_dice.mean(axis=1)\n",
    "df_dice.loc['Volume Avg'] = df_dice.mean(axis=0)\n",
    "df_dice = df_dice.rename(index=segment_names)\n",
    "df_dice.index.names = ['Segments']\n",
    "df_dice.to_csv(os.path.join(result_dir, \"test_dice.csv\"))\n",
    "\n",
    "    \n",
    "print('_'*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
